{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "eLMe6PwMj3V6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "from pandas.api.types import is_numeric_dtype"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generating a dataset with highly correlated features:\n",
        "import numpy as np\n",
        "def gen_cor_series(x,epsilon):\n",
        "    x1 = 2*x + (epsilon*np.random.random() -0.5 )\n",
        "    x2 = 3*x + (epsilon*np.random.random() -0.5 )\n",
        "    x3 = x+5 + (epsilon*np.random.random() -0.5 )\n",
        "    x4 = x*x + (epsilon*np.random.random() -0.5 )\n",
        "    x5 = 5*x+7 + (epsilon*np.random.random() -0.5 )\n",
        "    x6 = x*x-4 + (epsilon*np.random.random() -0.5 )\n",
        "    x7 = 6*x*x+3 + (epsilon*np.random.random() -0.5 )\n",
        "    yt = 7*x-6 + (epsilon*np.random.random() -0.5 )\n",
        "    return x1,x2,x3,x4,x5,x6,x7,yt \n",
        "    #return x1,x2,x3,x4,x5"
      ],
      "metadata": {
        "id": "lnHOCIccqIl1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(-10,10,0.1)\n",
        "np.random.shuffle(x)\n",
        "eps = 5\n",
        "x1,x2,x3,x4,x5,x6,x7,yt= gen_cor_series(x,eps)"
      ],
      "metadata": {
        "id": "awuzQggwn1A9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([x,x1,x2,x3,x4,x5,x6,x7,yt])"
      ],
      "metadata": {
        "id": "jTjW7e0LqR2f"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)\n",
        "df = df.transpose()"
      ],
      "metadata": {
        "id": "_Q05TBJPq-Lo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns=[\"x\",\"x1\",\"x2\",\"x3\",\"x4\",\"x5\",\"x6\",\"x7\",\"yt\"]\n",
        "temp = df\n",
        "inp_features = df.drop(\"yt\",axis=1)\n",
        "out_features = df[\"yt\"]"
      ],
      "metadata": {
        "id": "qBQ_iV9hrPXn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxr2score = -math.inf\n",
        "r2lam =0\n",
        "r2alph=0\n",
        "minloss = math.inf\n",
        "losslam=0\n",
        "lossalph=0\n",
        "lam = [10e-15, 10e-10, 10e-5,10e-3, 0, 1, 10, 20]\n",
        "learning_rate = [0.0001,0.001,0.01,0.1,1,10]\n",
        "for l in lam:\n",
        "  for a in learning_rate:\n",
        "    m=SGDRegressor(alpha=l,learning_rate='constant',eta0=a)\n",
        "    m.fit(inp_features,out_features)\n",
        "    ypred = m.predict(inp_features)\n",
        "    mse = mean_squared_error(out_features,ypred)\n",
        "    loss = mse +l*np.sum(m.coef_)\n",
        "    r2score = r2_score(out_features,ypred)\n",
        "    if maxr2score<r2score:\n",
        "      maxr2score=r2score\n",
        "      r2lam=l\n",
        "      r2alph=a\n",
        "    if minloss>loss:\n",
        "      minloss=loss\n",
        "      losslam=l\n",
        "      lossalph=a\n",
        "    # print(loss)\n",
        "    # print(mse)\n",
        "print(\"parameters for max r2: \")\n",
        "print(f\"r2vals={maxr2score} lambda={r2lam} alpha={r2alph}\")\n",
        "print(\"parameters for min loss: \")\n",
        "print(f\"lossvals={minloss} lambda={losslam} alpha={lossalph}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUlCsdrUr-sz",
        "outputId": "40660666-60e2-4042-92f9-5c60b660b453"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parameters for max r2: \n",
            "r2vals=-4.636513507082046e+20 lambda=0.01 alpha=0.0001\n",
            "parameters for min loss: \n",
            "lossvals=7.572782737265748e+23 lambda=0.01 alpha=0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-XTiiA80rVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2"
      ],
      "metadata": {
        "id": "t6DyOinA9g-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Hitters.csv\")\n",
        "# list_temp = [1,2,\"\"]\n",
        "# dftemp = pd.DataFrame(list_temp)\n",
        "# dftemp.columns=[\"X\"]\n",
        "# print(dftemp[\"X\"].mean())\n",
        "temp_df=df\n",
        "temp_df.dropna()\n",
        "meanval=temp_df[\"Salary\"].mean()\n",
        "df.fillna(meanval,inplace=True)\n"
      ],
      "metadata": {
        "id": "Uds3c9Y49lJh"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le_cols =['League', 'Division', 'NewLeague']\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "for c in le_cols:\n",
        "    df[c] = label_encoder.fit_transform(df[c])\n"
      ],
      "metadata": {
        "id": "rYw1gF1wHUZu"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_feats = df.drop(\"Salary\",axis=1)\n",
        "out_feats = df[\"Salary\"]"
      ],
      "metadata": {
        "id": "rDSqPEe-HvQ8"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = StandardScaler()\n",
        "inp_feats = scalar.fit_transform(inp_feats)"
      ],
      "metadata": {
        "id": "qhEX1J0OIJb2"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(inp_feats, out_feats, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "SZwsNmXtIb2z"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "m1 = LinearRegression()\n",
        "m2 = Ridge(alpha = 0.5748)\n",
        "m3 = Lasso(alpha = 0.5748)"
      ],
      "metadata": {
        "id": "LZazd1uCI-Op"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2SGyoWMLGnM",
        "outputId": "0ced078c-51eb-45b2-b0a3-2983513a348f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206    150.000000\n",
            "81     450.000000\n",
            "147    775.000000\n",
            "39     535.925882\n",
            "222    800.000000\n",
            "          ...    \n",
            "188     75.000000\n",
            "71     535.925882\n",
            "106    535.925882\n",
            "270    535.925882\n",
            "102    375.000000\n",
            "Name: Salary, Length: 225, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1.fit(X_train,y_train)\n",
        "m2.fit(X_train,y_train)\n",
        "m3.fit(X_train,y_train)\n",
        "p1=m1.predict(X_test)\n",
        "p2=m2.predict(X_test)\n",
        "p3=m3.predict(X_test)\n",
        "r2s1=r2_score(y_test,p1)\n",
        "r2s2=r2_score(y_test,p2)\n",
        "r2s3=r2_score(y_test,p3)\n",
        "print(r2s1)\n",
        "print(r2s2)\n",
        "print(r2s3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bac0f5ELJ5tp",
        "outputId": "d98317ee-dd36-42fb-acfb-1092771580f1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.48395666644591084\n",
            "0.48465284254618246\n",
            "0.48541354170746664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3"
      ],
      "metadata": {
        "id": "HymstRDeMQsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.linear_model import RidgeCV\n",
        "X, y = load_boston(return_X_y=True)\n",
        "ridge_cv = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
        "ridge_cv.fit(X, y)\n",
        "ridge_cv.score(X, y)"
      ],
      "metadata": {
        "id": "1VgPBIM4MPnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "X, y = load_boston(return_X_y=True)\n",
        "lasso_cv = LassoCV(cv=5, random_state=0).fit(X, y)\n",
        "lasso_cv.fit(X,y)\n",
        "lasso_cv.score(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px4aigeMN1h7",
        "outputId": "fe59d856-0ecc-4f1d-c408-1c78fa0532bd"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7024437179872696"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q5bqJlpaLDl7"
      }
    }
  ]
}